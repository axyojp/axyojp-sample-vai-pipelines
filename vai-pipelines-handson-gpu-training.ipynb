{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6807967-d798-49a0-876d-c12eae84eec6",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines Handson(Pytorch GPU training)\n",
    "- このハンズオンでは Vertex AI Pipelines で GPU を利用した Custom Training を実行するパイプラインを作成します。\n",
    "- 主に Continuous Training を意識したパイプラインになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447716d-57b9-46b4-abee-d3ff31038e2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7cad0-06db-4948-b11f-4f703758f31d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2025/02/12 時点では、Workbench で実行した場合にはこの辺がインストールされている。\n",
    "# KFP SDK version: 2.5.0\n",
    "# google-cloud-aiplatform==1.75.0\n",
    "# kfp==2.5.0\n",
    "# kfp-pipeline-spec==0.2.2\n",
    "# kfp-server-api==2.0.5\n",
    "\n",
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep -e aiplatform -e kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d192b7e1-a18c-4c9b-8a7b-a17667d262bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Workbench Instances などを利用している場合など、必要に応じて実施する。\n",
    "# uninstall については、バグ回避のために入れている。\n",
    "\n",
    "\n",
    "# !pip uninstall -y protobuf python3-protobuf\n",
    "# !pip install --no-cache-dir --upgrade \"kfp>2\" \\\n",
    "#                                         google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dfb5d-e612-4660-aa75-7c5802e664a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2025/02/12 時点では、Workbench で実行した場合には google-cloud-pipeline-components==2.18.0 がインストールされる。\n",
    "\n",
    "!pip3 install -U google-cloud-pipeline-components\n",
    "!pip3 freeze | grep google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf5a4c-e7e0-4dce-ac2a-176c614d9a78",
   "metadata": {},
   "source": [
    "## 環境変数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc216e0-db81-47e9-a1bf-b7d4b9af9ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shell_output = !gcloud config get project\n",
    "PROJECT_ID = shell_output[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca049f-0556-4ad9-9988-04b11651e483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"\n",
    "BQ_REGION = REGION.split(\"-\")[0].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1786d9d-4cfe-49b7-9297-92e436efe22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ab395-e6cc-457c-b22a-bfac555653e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Workbench 等を利用する時に特別な設定を行ったいない場合は、Default の GCE のサービスアカウントが利用される。\n",
    "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce684ac-f20d-4902-985d-19a73192d36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your service account from gcloud\n",
    "    if not IS_COLAB:\n",
    "        shell_output = !gcloud auth list 2>/dev/null\n",
    "        SERVICE_ACCOUNT = shell_output[2].replace(\"*\", \"\").strip()\n",
    "\n",
    "    else:  # IS_COLAB:\n",
    "        shell_output = ! gcloud projects describe  $PROJECT_ID\n",
    "        project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
    "        SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
    "\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746df87-ad24-4071-b53e-e2c3671e1272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = %env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "date_string = !date '+%Y%m%d%H%M%S'\n",
    "YYYYMMDDHHmmSS = date_string[0]\n",
    "\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_URI}/vai_pipelines_handson_pipeline_gpu_training_{YYYYMMDDHHmmSS}\"  # This is where all pipeline artifacts are sent. You'll need to ensure the bucket is created ahead of time\n",
    "PIPELINE_ROOT\n",
    "print(f\"PIPELINE_ROOT: {PIPELINE_ROOT}\")\n",
    "\n",
    "\n",
    "CONTAINER_IMAGE_URL=f\"us-central1-docker.pkg.dev/{PROJECT_ID}/custom-prediction-pytorch-cpu/custom-prediction-pytorch-cpu:latest\"\n",
    "print(CONTAINER_IMAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc8190-3a12-4c14-b47a-e8e1ba58c51c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 環境構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a7464-b3ad-436a-a811-4aa803448d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d508fc-ed0f-47b5-869c-b47e816da3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ffcc9-806f-4017-9208-f173b12bc9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397bdba-06c2-4f4f-b8c6-afe24a66d5af",
   "metadata": {},
   "source": [
    "## Vertex AI Pipelines の利用準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d936cce-b4b3-4787-9652-ba7000072e0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d351a-18de-48fd-a49c-9d3b5430144f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "import kfp\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import Artifact, Dataset, Input, Metrics, Model, Output, component\n",
    "from google_cloud_pipeline_components.v1.vertex_notification_email import VertexNotificationEmailOp\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from google_cloud_pipeline_components.v1.custom_job import create_custom_training_job_from_component\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "from kfp.dsl import importer_node\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f585c-697f-41f5-9fa8-9c979509fdb3",
   "metadata": {},
   "source": [
    "### Vertex AI の初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553be454-af3c-4859-8537-3149dacfac0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07914ed8-6fba-486b-bf4e-cab872893360",
   "metadata": {
    "tags": []
   },
   "source": [
    "## パイプラインコンポーネントの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf37b4-83de-4761-9fbb-f48538d0c301",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GPU をつかったカスタム トレーニングを行うコンポーネント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedc368-4c4a-424f-9693-8bfd6aed3a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image='us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-3.py310:latest',\n",
    "    packages_to_install=[\n",
    "        \"torch==2.6.0\",\n",
    "        \"torchvision==0.21.0\",\n",
    "        \"numpy==1.26.4\"\n",
    "    ],\n",
    ")\n",
    "def pytorch_training(\n",
    "    model: Output[Model],\n",
    "    metrics: Output[Metrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"auc\", float), (\"model_uri\", str)]) :\n",
    "    # https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.data import DataLoader\n",
    "    from torchvision import datasets\n",
    "    from torchvision.transforms import ToTensor\n",
    " \n",
    "    import os\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "    print(f\"Using {device} device\")\n",
    "    \n",
    "    \n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    \n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "        break\n",
    "\n",
    "        \n",
    "    # Define model\n",
    "    class NeuralNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(28*28, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 10)\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.flatten(x)\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits\n",
    "\n",
    "    nn_model = NeuralNetwork().to(device)\n",
    "    print(nn_model)\n",
    "    \n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(nn_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    \n",
    "    def train(dataloader, model, loss_fn, optimizer):\n",
    "        size = len(dataloader.dataset)\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "                \n",
    "                \n",
    "    def test(dataloader, model, loss_fn):\n",
    "        size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    \n",
    "    epochs = 5\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, nn_model, loss_fn, optimizer)\n",
    "        test(test_dataloader, nn_model, loss_fn)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "\n",
    "    # Export the model to a file\n",
    "    print(f'model.path: {model.path}')\n",
    "    print(f'os.path.join(model.path, \"model.pth\"): {os.path.join(model.path, \"model.pth\")}')\n",
    "    os.makedirs(model.path, exist_ok=True)\n",
    "    print(f'The directory has been created.')\n",
    "    torch.save(nn_model.state_dict(), os.path.join(model.path, \"model.pth\"))\n",
    "    print(\"Saved PyTorch Model State to model.pth\")\n",
    "    \n",
    "    \n",
    "    auc = 0.9\n",
    "\n",
    "    \n",
    "    return (auc, model.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66ef706-c94f-4cd2-bf42-56ce5af04150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format=\"value(projectNumber)\"\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "print(f'PROJECT_NUMBER: {PROJECT_NUMBER}')\n",
    "\n",
    "# NETWORK = !gcloud compute networks describe default --format=\"value(id)\"\n",
    "# NETWORK = NETWORK[0]\n",
    "# NETWORK='default'\n",
    "# print(f'NETWORK: {NETWORK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815048df-0264-42af-817d-753629a229ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_training_job = create_custom_training_job_from_component(\n",
    "    pytorch_training,\n",
    "    display_name = 'pytorch_training',\n",
    "    machine_type = 'g2-standard-16',\n",
    "    accelerator_type='NVIDIA_L4',\n",
    "    accelerator_count='1',\n",
    "    boot_disk_type='pd-ssd',\n",
    "    boot_disk_size_gb='100',\n",
    "    # network=f'projects/{PROJECT_NUMBER}/global/networks/{NETWORK}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7254f-01e9-4ff7-8d1f-79d705577753",
   "metadata": {
    "tags": []
   },
   "source": [
    "## モデルサービングのためのコンテナを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c062f-f8f3-4a47-a1e6-017a45d95c72",
   "metadata": {},
   "source": [
    "### Artifact Registry にリポジトリを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b6153-c8a0-4038-b55a-dcedad3ca96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud artifacts repositories create custom-prediction-pytorch-cpu \\\n",
    " --repository-format=docker \\\n",
    " --location=us-central1\n",
    "!gcloud artifacts repositories list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1cdc77-8513-4478-93bf-2a31d36c3d35",
   "metadata": {},
   "source": [
    "### コンテナを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0c2d9-f766-420a-b378-ed3263a4f053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker build \\\n",
    "  --tag=us-central1-docker.pkg.dev/{PROJECT_ID}/custom-prediction-pytorch-cpu/custom-prediction-pytorch-cpu \\\n",
    "  -f app_prediction_pytorch_cpu/Dockerfile \\\n",
    "  app_prediction_pytorch_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10673d25-b428-4b65-aec0-f365ab898fe4",
   "metadata": {},
   "source": [
    "### Artifact Registry に登録（Push）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c52fd2-c186-4127-850b-fd894154b25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud auth configure-docker --quiet us-central1-docker.pkg.dev\n",
    "!docker push us-central1-docker.pkg.dev/{PROJECT_ID}/custom-prediction-pytorch-cpu/custom-prediction-pytorch-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc4f696-d691-4ac7-a3cb-760cf08071e1",
   "metadata": {},
   "source": [
    "## パイプラインの定義（定義したコンポーネントを利用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97576b0c-2b5d-45f6-8f88-6005ad9cf316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTAINER_IMAGE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9ea86-7c2b-463d-aec6-b74ec27362cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"vai-pipelines-handson-gpu-training\",\n",
    ")\n",
    "def pipeline():\n",
    "    \n",
    "    training_job_task = custom_training_job(\n",
    "        project=PROJECT_ID,\n",
    "        location=REGION,\n",
    "    ).set_display_name('training-job-task')\n",
    "    \n",
    "    \n",
    "    import_unmanaged_model_task = importer_node.importer(\n",
    "        artifact_uri=training_job_task.outputs[\"model_uri\"],\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"artifactUri\": training_job_task.outputs[\"model_uri\"],\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": CONTAINER_IMAGE_URL,\n",
    "                \"healthRoute\": \"/\",\n",
    "                \"predictRoute\": \"/predict\",\n",
    "                \"env\": [\n",
    "                    {\n",
    "                        \"name\": \"SRC_MODEL_URI\",\n",
    "                        \"value\": training_job_task.outputs[\"model_uri\"]\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "    model_task = ModelUploadOp(\n",
    "        project=PROJECT_ID,\n",
    "        display_name=\"custom-prediction-pytorch-cpu\",\n",
    "        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222bac1-1575-4d5d-960f-0e3fcf7406ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## パイプラインのコンパイル（YAML 生成）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5687684-70ae-4269-8512-9c75b2815e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline-gpu-training.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb349bdc-06b9-4d0e-a178-cecbf74f6b30",
   "metadata": {},
   "source": [
    "## パイプラインの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecdf2c-268f-4281-8aac-d7357579bfc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"vai-pipelines-handson-gpu-training\",\n",
    "    template_path=\"pipeline-gpu-training.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ea446-a919-4773-98fe-f776ba16d1a3",
   "metadata": {},
   "source": [
    "## おまけ（Cloud Run への Deploy）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b28d16-fd51-4cc8-b2ed-67218bbfa310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-run==0.10.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af370ba-df0b-4d28-9b5a-133f41643233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import run_v2\n",
    "from google.cloud.run_v2 import types, services\n",
    "\n",
    "def create_cloud_run_service(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    service_name: str,\n",
    "    image_uri: str,\n",
    "    src_model_uri: str,\n",
    "):\n",
    "    \"\"\"Cloud Run サービスを作成します.\"\"\"\n",
    "\n",
    "    client = services.services.ServicesClient()\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    service = types.Service()\n",
    "    service.template.containers = [\n",
    "        types.Container(\n",
    "            image=image_uri,\n",
    "            env=[types.EnvVar(name=\"SRC_MODEL_URI\", value=src_model_uri)],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    request = run_v2.CreateServiceRequest(\n",
    "        parent=parent,\n",
    "        service=service,\n",
    "        service_id=service_name,\n",
    "    )\n",
    "\n",
    "    operation = client.create_service(request=request)\n",
    "    print(f\"サービス {service_name} の作成を開始しました。\")\n",
    "    result = operation.result()\n",
    "    print(f\"サービス {service_name} が作成されました: {result.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3fd46-e3cc-4339-a29f-1046984ef6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = PROJECT_ID  # プロジェクトID\n",
    "location = REGION  # Cloud Run のロケーション（例: \"us-central1\"）\n",
    "service_name = \"app-predict-pytorch-cpu\"  # サービス名\n",
    "image_uri = CONTAINER_IMAGE_URL  # ビルドされたコンテナイメージ URI (Artifact Registry の URI)\n",
    "src_model_uri = \"更新してください\" # GCS のモデルファイルの URI\n",
    "\n",
    "create_cloud_run_service(\n",
    "    project_id, location, service_name, image_uri, src_model_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2f386-22c2-4604-ba3b-2a70376cf438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "URL=!gcloud run services describe {service_name} --region {location} --format json | jq -r '.status.url'\n",
    "URL=URL[0]\n",
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad8ec8-5258-480c-9516-cfac97f92626",
   "metadata": {
    "tags": []
   },
   "source": [
    "curl -X POST \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"instances\":[{\"key1\":\"val1\"}]}' \\\n",
    "     \"$URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e8fec-29f8-4cf1-8117-4098a014c8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b57ccf-c52e-4016-90ff-9190452f4242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
